{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8jKiDIBAima"
      },
      "source": [
        "# Cover Type Classification\n",
        "\n",
        "## Objective: Build a deep learning model to predict the forest cover type from different cartographic variables.\n",
        "\n",
        "### Given\n",
        "    1. Cover Types:\n",
        "      - Spruce/Fir\n",
        "      - Lodgepole Pine\n",
        "      - Ponderosa Pine\n",
        "      - Cottonwood/Willow\n",
        "      - Aspen\n",
        "      - Douglas-fir\n",
        "      - Krummholz\n",
        "\n",
        "    2. Dataset\n",
        "      - File: `cover_data.csv`\n",
        "      - Contains 581,012 observations\n",
        "      - Each observation has 55 columns (54 features and the last one being the class)\n",
        "\n",
        "### Assumptions\n",
        "    1. Test Data: No separate test dataset provided, so a portion of the input must be held out as test data.\n",
        "    2. Prediction Focus: No information on whether to prioritize precision or recall, so both should be maximized.\n",
        "\n",
        "### Expected Output\n",
        "    1. A high-performing deep learning model.\n",
        "    2. Performance metrics over epochs (accuracy and loss plots).\n",
        "    3. Classification metrics:\n",
        "      - Heatmap of the confusion matrix\n",
        "      - Classification report\n",
        "    4. Conclusions, thoughts, and suggestions for improving classification accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFcHVSdfAimg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sweetviz as sv\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0IUzsDLAiml"
      },
      "outputs": [],
      "source": [
        "# Disable those annoying warnings\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Turn off GPU usage for tf\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocaInuvfAimn"
      },
      "source": [
        "### Define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DcZ49LXAimo"
      },
      "outputs": [],
      "source": [
        "def prep_data(raw_df):\n",
        "    \"\"\"\n",
        "    Prepare data that can be readily consumed by ML/DL algorithms.\n",
        "    - separate features from class variables\n",
        "    - split into training and testing dataset\n",
        "    - scale numerical data\n",
        "\n",
        "    param: a dataframe of input data\n",
        "    output: X_train_normalized, X_test_normalized, y_train, y_test\n",
        "    \"\"\"\n",
        "    raw_data = raw_df.values\n",
        "    X, y = raw_data[:, :-1], raw_data[:, -1]\n",
        "\n",
        "    # Split into train and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "    # normalize data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_normalized = scaler.fit_transform(X_train)\n",
        "    X_test_normalized = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_normalized, X_test_normalized, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCBD9-DSAimp"
      },
      "outputs": [],
      "source": [
        "def build_model(num_features):\n",
        "    \"\"\"\n",
        "    Build the model architecture (and compile it).\n",
        "    input: number of features\n",
        "    output: Keras model object.\n",
        "    \"\"\"\n",
        "    classifier = keras.Sequential()\n",
        "    classifier.add(layers.Dense(64, input_dim=num_features, activation='relu'))\n",
        "    #classifier.add(layers.Dropout(0.3))\n",
        "    classifier.add(layers.Dense(32, activation='relu'))\n",
        "    #classifier.add(layers.Dropout(0.3))\n",
        "    classifier.add(layers.Dense(8, activation='softmax'))\n",
        "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmRzkUv9Aimq"
      },
      "outputs": [],
      "source": [
        "def plot_heatmap(class_names, y_pred, y_test):\n",
        "    \"\"\"\n",
        "    Function to compute a Confusion Matrix and plot a heatmap based on the matrix.\n",
        "    input: class names, y-predicted, y-test (ground-truth)\n",
        "    output: a PNG file of the heatmap.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(15, 15))\n",
        "    heatmap = sns.heatmap(cm, fmt='g', cmap='Blues', annot=True, ax=ax)\n",
        "    ax.set_xlabel('Predicted class')\n",
        "    ax.set_ylabel('True class')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(class_names)\n",
        "    ax.yaxis.set_ticklabels(class_names)\n",
        "    # Save the heatmap to file\n",
        "    heatmapfig = heatmap.get_figure()\n",
        "    heatmapfig.savefig(f'../output/confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kece7DwoAimq"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, param):\n",
        "    \"\"\"\n",
        "    Shows how the model performs (in terms of accuracy and loss) over several epochs.\n",
        "    \"\"\"\n",
        "    if param == 'acc':\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'val'], loc='upper left')\n",
        "        plt.show()\n",
        "    elif param == 'loss':\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'val'], loc='upper right')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-jQhpZsRowx"
      },
      "source": [
        "### The main function below drives the entire code. It prepares the dataset, builds a model with appropriate parameters, evaluates the model and predicts on the test data. Finally, plots some performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N55BD9FpRow6"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    infile = '../input/covertype/cover_data.csv'\n",
        "    raw_df = pd.read_csv(infile)\n",
        "\n",
        "    # EDA\n",
        "    # Uncomment the below two lines to run EDA. Takes > 10 min to run.\n",
        "    #my_report = sv.analyze(raw_df)\n",
        "    #my_report.show_html()\n",
        "\n",
        "    cols = raw_df.columns.tolist()\n",
        "    features, label = cols[:-1], cols[-1]\n",
        "    X_train, X_test, y_train, y_test = prep_data(raw_df)\n",
        "\n",
        "    # Build a DL model\n",
        "    num_features = len(features)\n",
        "    model = build_model(num_features)\n",
        "\n",
        "    print(\"Summary report of Keras classifier:\")\n",
        "    model.summary()\n",
        "\n",
        "    num_epochs = 100\n",
        "    batch_size = 1024\n",
        "    earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=3)\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=num_epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[earlystop_callback],\n",
        "                        validation_split=0.1,\n",
        "                        verbose=1)\n",
        "\n",
        "    plot_history(history, 'acc')\n",
        "    plot_history(history, 'loss')\n",
        "\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Test loss: {score[0]}')\n",
        "    print(f'Test accuracy: {score[1]}')\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Convert the pred to discrete values\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    class_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
        "                   'Ponderosa Pine', 'Cottonwood/Willow',\n",
        "                   'Aspen', 'Douglas-fir', 'Krummholz']\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "    plot_heatmap(class_names, y_pred, y_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}